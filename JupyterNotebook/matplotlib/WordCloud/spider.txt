import requests
import re
import pymysql

BASE_URL = 'http://cd.ganji.com'

MYSQL_HOST = 'localhost'

MYSQL_PORT = 3306

MYSQL_USER = 'root'

MYSQL_PASSWORD = '123456'

MYSQL_DATABASE = 'ganjiDB'

NEXT_PAGE_NUM = 3




def get_page_html(url):
    """
        获取首页HTML源代码
    """

    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/69.0.3497.100 Safari/537.36'
    }
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        return response.text
    return None


class MySQL():
    def __init__(self, host=MYSQL_HOST, username=MYSQL_USER, password=MYSQL_PASSWORD, port=MYSQL_PORT,
                 database=MYSQL_DATABASE):
        """
            MySQL初始化
        """
        try:
            self.db = pymysql.connect(host, username, password, database, charset='utf8', port=port)
            self.cursor = self.db.cursor()
        except pymysql.MySQLError as e:
            print(e.args)
    
    def insert(self, table, data):
        """
            插入数据
        """
        keys = ', '.join(data.keys())
        values = ', '.join(['%s'] * len(data))
        sql_query = 'insert into %s (%s) values (%s)' % (table, keys, values)
        try:
            self.cursor.execute(sql_query, tuple(data.values()))
            self.db.commit()
        except pymysql.MySQLError as e:
            print(e.args)
            self.db.rollback()

    def select(self, table, data):
        """
            读取数据
        """
        sql_query = 'select * from %s ' % (table)
        try:
            self.cursor.execute(sql_query)
            return self.cursor.fetchall()

        except pymysql.MySQLError as e:
            print(e.args)
            self.db.rollback()

mysql = MySQL()




def getTypeURL(html):
    """
        提取成都招聘热门职位的URL
    """
    # 提取成都招聘热门职位<div class="f-hot"></div>
    # 正则
    print('-'*100)
    print('-----获取类别-----')
    pattern1 = re.compile('<div class="f-hot">([\s\S]*?)</div>', re.S)
    types_html = re.findall(pattern1, html)
    
    # 提取详细分类URL<a href="xx">xx</a>
    pattern2 = re.compile('<a .*?href="(.*?)".*?>(.*?)</a>', re.S)
    items = re.findall(pattern2, str(types_html))

    #print(items)
    # 添加到MySQL
    for item in items:
        print('得到类别：%s' % item[1])
        data =  {
            'url': BASE_URL + item[0],
            'typename': item[1]
        }
        # mysql.insert('types_url', data)

        
def getJobsURL(types_url):
    """
        查询数据库获得类别的URL，根据类别URL获取职位的URL
    """
    for row in types_url:
        print('---------- 获取 %s 类工作 ----------' % (row[2]))
        # 获取分类HTML
        type_html = get_page_html(row[1])
        # 获取工作URL
        getJobURL(type_html)

        current_html = type_html
        # 获取类别的下一页，循环次数为NEXT_PAGE_NUM
        for i in range(NEXT_PAGE_NUM):
            #print(current_html)
            current_html = getNextPage(current_html)    # 返回值为当前页的下一页作为下次循环的当前页
        


def getJobURL(type_html):
    """
        根据类别页获取工作URL，并加入MySQL
    """

    # 正则提取工作URL <dl class="list-noimg job-list clearfix new-dl".*?>([\s\S]*?)</dl>
    pattern1 = re.compile('<dl class="list-noimg job-list clearfix new-dl".*?>([\s\S]*?)</dl>', re.S)
    jobs_html = re.findall(pattern1, type_html)
    
    # 提取每个工作的URL<a href="([\s\S]*?)"[\s\S]*?class="list_title[\s\S]*?"[\s\S]*?>([\s\S]*?)</a>
    pattern2 = re.compile('<a href="([\s\S]*?)"[\s\S]*?class="list_title[\s\S]*?"[\s\S]*?>([\s\S]*?)</a>', re.S)
    items = re.findall(pattern2, str(jobs_html))

    # 添加到MySQL
    for item in items:
        print('te')
        print(item[1])
        data = {
            'url': BASE_URL + item[0],
            'jobname': item[1].strip()  # 去除首尾空白
        }
    # mysql.insert('jobs_url', data)



def getNextPage(current_html):
    """
        获取该类别的下一页
    """
    if current_html == None:
        return None
    # 提取分页ul <ul class="pageLink clearfix">([\s\S]*?)</ul>
    pattern1 = re.compile('<ul class="pageLink clearfix">([\s\S]*?)</ul>', re.S)
    url_html = re.findall(pattern1, current_html)
    
    # 该类别的分页  href="(.*?)"
    pattern2 = re.compile('href="(.*?)"', re.S)

    # 下页URL
    i = 0
    next_page_url = None
    for url in re.findall(pattern2, str(url_html)):
        next_page_url = str(url)

    # 获取工作URL
    if next_page_url != None:
        
        next_page_url = BASE_URL + next_page_url
        print('---------- 获取子页 %s ----------' % (next_page_url))

        next_page_html = get_page_html(next_page_url)
        getJobURL(next_page_html)
        # 返回下一页的HTML
        return next_page_html



def getJobInfo(jobs_url):
    """
        根据数据库得到的job URL得到相关信息，并存入MySQL
    """
    print("aaaaaa")
    #for url in jobs_url:
    # html = get_page_html(url[1])
    html = get_page_html('http://cd.ganji.com/zpshichangyingxiao/2759567089x.htm')
    
    # 职位名
    jobname = re.search(r'<div class="title-line clearfix">[\s\S]*?<p>([\s\S]*?)</p>([\s\S]*?)</div>', html, re.M|re.I)
    print(jobname.group(1))
    
    # 工资
    salary = re.search(r'<div class="salary-line">[\s\S]*?<b>([\s\S]*?)</b>[\s\S]*?<i>([\s\S]*?)</i>[\s\S]*?</div>', html, re.M|re.I)
    print(salary.group(1) + salary.group(2))
    
    # 工作地点
    location = re.search(r'<div class="location-line clearfix">[\s\S]*?<p>([\s\S]*?)<[\s\S]*?</p>[\s\S]*?</div>', html, re.M|re.I)
    print(location)

    # 工作地点
    location = re.search(r'<div class="location-line clearfix">[\s\S]*?<p>([\s\S]*?)<[\s\S]*?</p>[\s\S]*?</div>', html, re.M|re.I)
    print(location)

    # 工作地点
    location = re.search(r'<div class="location-line clearfix">[\s\S]*?<p>([\s\S]*?)<[\s\S]*?</p>[\s\S]*?</div>', html, re.M|re.I)
    print(location)





def main():
    # # 1.获取首页HTML源代码
    # html = get_page_html(BASE_URL + '/zhaopin')
    # if html == None:
    #     print('获取首页失败!')
    #     exit(0)
    # #print(html)

    # # 2.提取HTML代码，获得成都招聘热门职位的URL，并加入MySQL
    # getTypeURL(html)

    # # 3.从数据库获取类别的URL，提取每个类别下的职位URL
    # types_url = mysql.select('types_url', None)
    # getJobsURL(types_url)

    # 4.从数据库获取职位的URL，得到HTML获取相关信息并加入MySQL
    jobs_url = mysql.select('jobs_url', None)
    print("bbb")
    getJobInfo(jobs_url)

        


if __name__ == '__main__':
    main()






"""
-- 创建数据库
CREATE DATABASE IF NOT EXISTS ganjiDB DEFAULT CHARSET utf8 COLLATE utf8_general_ci;

USE ganjiDB;

-- 创建分类url表
CREATE TABLE types_url (
    id INT(11) NOT NULL AUTO_INCREMENT,
    url VARCHAR(255) NOT NULL,
    typename VARCHAR(255) NOT NULL,
    PRIMARY KEY(id)
)ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- 创建职位url表
CREATE TABLE jobs_url (
    id INT(11) NOT NULL AUTO_INCREMENT,
    url VARCHAR(255) NOT NULL,
    jobname VARCHAR(255) NOT NULL,
    PRIMARY KEY(id)
)ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- 创建职位信息表
CREATE TABLE jobs_info (
    id INT(11) NOT NULL AUTO_INCREMENT,
    name VARCHAR(255) NOT NULL,
    salary VARCHAR(255) NOT NULL,
    company VARCHAR(255) NOT NULL,
    location VARCHAR(255) NOT NULL,
    description VARCHAR(255) DEFAULT NULL,
    PRIMARY KEY(id)
)ENGINE=InnoDB DEFAULT CHARSET=utf8;

"""